{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 13:39:16 -04:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.3 s (started: 2021-04-12 13:39:16 -04:00)\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.5 s (started: 2021-04-12 13:39:26 -04:00)\n"
     ]
    }
   ],
   "source": [
    "reviews = spark.read.json('yelp_academic_dataset_review.json')\n",
    "reviews = reviews.select(['business_id', 'text', 'stars'])\n",
    "reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680910.1867572156"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 13:39:56 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# 5.89 / x = 0.5\n",
    "# 0.5 * x = 5.89\n",
    "x = 5.89 / 0.5\n",
    "8021122 / x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 63 ms (started: 2021-04-12 13:39:56 -04:00)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType\n",
    "reviews = reviews.withColumn('stars', col('stars').cast(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset data for Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 13:39:56 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# x = (1/10)\n",
    "# subset_df, large_df = reviews.randomSplit([x, 1 - x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 13:39:57 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# subset_df.coalesce(1).write.format('json').save('reviews_1-10.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.84 s (started: 2021-04-12 13:39:57 -04:00)\n"
     ]
    }
   ],
   "source": [
    "businesses = spark.read.json('yelp_academic_dataset_business.json')\n",
    "businesses = businesses.select(['business_id', 'categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5055992"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.62 s (started: 2021-04-12 13:39:58 -04:00)\n"
     ]
    }
   ],
   "source": [
    "restaurants = businesses.filter(businesses.categories.contains('Restaurants'))\n",
    "restaurant_reviews = reviews.join(restaurants, \"business_id\", \"inner\")\n",
    "restaurant_reviews = restaurant_reviews.select(['text', 'stars'])\n",
    "restaurant_reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1256088"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.1 s (started: 2021-04-12 13:40:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "five_stars = restaurant_reviews.filter(restaurant_reviews.stars == 5.0)\n",
    "one_stars = restaurant_reviews.filter(restaurant_reviews.stars == 1.0)\n",
    "num_one_stars = one_stars.count()\n",
    "five_stars = five_stars.limit(num_one_stars)\n",
    "one_or_five_stars = five_stars.union(one_stars)\n",
    "num_one_stars * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.7 s (started: 2021-04-12 13:40:18 -04:00)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol = 'stars', outputCol = 'categoryIndex')\n",
    "indexed = indexer.fit(one_or_five_stars).transform(one_or_five_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5420878155033724"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 13:40:39 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# 680910 rows = ~500MB\n",
    "# 1256088 * x = 680910\n",
    "680910 / 1256088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125587\n",
      "time: 30.6 s (started: 2021-04-12 13:40:39 -04:00)\n"
     ]
    }
   ],
   "source": [
    "x = 0.1\n",
    "subset_df, large_df = indexed.randomSplit([x, 1 - x])\n",
    "subset_count = subset_df.count()\n",
    "print(subset_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text=\"!!AMAZING RESTAURANT!!\\n\\nI have got to buy a fondue set now lol.\\n\\nThe creamy spinach artichoke cheese dip, minced walnut melted milk chocolate, and mixture of marinated meats were incredibly delicious but what earns this place without any doubt 5 Stars instead 3 or 4, is their incredible service.\\n\\nRichard our server was sociable and almost too considerate lol (we stayed to 1:20am even though this place closed at 11pm!!!).\\n\\nSteve the manager treated my girlfriend and I with a card signed by most of the restaurant staff and some treats to make the anniversary of our 1st date really special.\\n\\nThis place isn't for the cheap at heart or those with quality taste but don't have a lot of spending cash on them.\\n\\nDefinitely GO!! but I would suggest you go if you:\\n1) are in a group bigger than 4\\n2) just don't mind spending more than $20-40 on an entree\\n3) want to try something different/new\\n4) are looking to make a romantic occasion really special (let the restaurant know about your special occasion)\\n5) or want to treat someone you care about who is isn't particular in general, to something they haven't tried before\", stars='5.0', categoryIndex=1.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.5 s (started: 2021-04-12 13:41:10 -04:00)\n"
     ]
    }
   ],
   "source": [
    "subset_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "time: 10.5 s (started: 2021-04-12 13:41:28 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Build NLP preprocessing pipeline\n",
    "from sparknlp.base import DocumentAssembler\n",
    "document_assembler = DocumentAssembler() \\\n",
    ".setInputCol('text') \\\n",
    ".setOutputCol('document')\n",
    "from sparknlp.annotator import Tokenizer\n",
    "tokenizer = Tokenizer() \\\n",
    ".setInputCols(['document']) \\\n",
    ".setOutputCol('tokenized') \\\n",
    ".setContextChars(['(', ')']) \\\n",
    ".setSplitChars(['-'])\n",
    "from sparknlp.annotator import Normalizer\n",
    "normalizer = Normalizer() \\\n",
    ".setInputCols(['tokenized']) \\\n",
    ".setOutputCol('normalized') \\\n",
    ".setLowercase(True) \\\n",
    ".setCleanupPatterns(['[^A-Za-z]'])\n",
    "from sparknlp.annotator import LemmatizerModel\n",
    "lemmatizer = LemmatizerModel \\\n",
    ".pretrained() \\\n",
    ".setInputCols(['normalized']) \\\n",
    ".setOutputCol('lemmatized')\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = stopwords.words('english')\n",
    "from sparknlp.annotator import StopWordsCleaner\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    ".setInputCols(['lemmatized']) \\\n",
    ".setOutputCol('unigrams') \\\n",
    ".setStopWords(nltk_stopwords)\n",
    "from sparknlp.annotator import NGramGenerator\n",
    "ngrammer = NGramGenerator() \\\n",
    "    .setInputCols(['unigrams']) \\\n",
    "    .setOutputCol('ngrams') \\\n",
    "    .setN(2) \\\n",
    "    .setEnableCumulative(True) \\\n",
    "    .setDelimiter('_')\n",
    "from sparknlp.base import Finisher\n",
    "finisher = Finisher() \\\n",
    ".setInputCols(['unigrams', 'ngrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 13:41:39 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Assemble pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline() \\\n",
    ".setStages([document_assembler,\n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            lemmatizer,\n",
    "            stopwords_cleaner,\n",
    "            ngrammer,\n",
    "            finisher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 656 ms (started: 2021-04-12 13:41:39 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Fit pipeline\n",
    "processed_reviews = pipeline.fit(subset_df).transform(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text=\"!!AMAZING RESTAURANT!!\\n\\nI have got to buy a fondue set now lol.\\n\\nThe creamy spinach artichoke cheese dip, minced walnut melted milk chocolate, and mixture of marinated meats were incredibly delicious but what earns this place without any doubt 5 Stars instead 3 or 4, is their incredible service.\\n\\nRichard our server was sociable and almost too considerate lol (we stayed to 1:20am even though this place closed at 11pm!!!).\\n\\nSteve the manager treated my girlfriend and I with a card signed by most of the restaurant staff and some treats to make the anniversary of our 1st date really special.\\n\\nThis place isn't for the cheap at heart or those with quality taste but don't have a lot of spending cash on them.\\n\\nDefinitely GO!! but I would suggest you go if you:\\n1) are in a group bigger than 4\\n2) just don't mind spending more than $20-40 on an entree\\n3) want to try something different/new\\n4) are looking to make a romantic occasion really special (let the restaurant know about your special occasion)\\n5) or want to treat someone you care about who is isn't particular in general, to something they haven't tried before\", stars='5.0', categoryIndex=1.0, finished_unigrams=['amazing', 'restaurant', 'get', 'buy', 'fondue', 'set', 'lol', 'creamy', 'spinach', 'artichoke', 'cheese', 'dip', 'mince', 'walnut', 'melt', 'milk', 'chocolate', 'mixture', 'marinate', 'meat', 'incredibly', 'delicious', 'earn', 'place', 'without', 'doubt', 'star', 'instead', 'incredible', 'service', 'richard', 'server', 'sociable', 'almost', 'considerate', 'lol', 'stay', 'even', 'though', 'place', 'close', 'pm', 'steve', 'manager', 'treat', 'girlfriend', 'card', 'sign', 'restaurant', 'staff', 'treat', 'make', 'anniversary', 'st', 'date', 'really', 'special', 'place', 'isnt', 'cheap', 'heart', 'quality', 'taste', 'dont', 'lot', 'spend', 'cash', 'definitely', 'go', 'would', 'suggest', 'go', 'group', 'big', 'dont', 'mind', 'spend', 'entree', 'want', 'try', 'something', 'differentnew', 'look', 'make', 'romantic', 'occasion', 'really', 'special', 'let', 'restaurant', 'know', 'special', 'occasion', 'want', 'treat', 'someone', 'care', 'isnt', 'particular', 'general', 'something', 'havent', 'try'], finished_ngrams=['amazing', 'restaurant', 'get', 'buy', 'fondue', 'set', 'lol', 'creamy', 'spinach', 'artichoke', 'cheese', 'dip', 'mince', 'walnut', 'melt', 'milk', 'chocolate', 'mixture', 'marinate', 'meat', 'incredibly', 'delicious', 'earn', 'place', 'without', 'doubt', 'star', 'instead', 'incredible', 'service', 'richard', 'server', 'sociable', 'almost', 'considerate', 'lol', 'stay', 'even', 'though', 'place', 'close', 'pm', 'steve', 'manager', 'treat', 'girlfriend', 'card', 'sign', 'restaurant', 'staff', 'treat', 'make', 'anniversary', 'st', 'date', 'really', 'special', 'place', 'isnt', 'cheap', 'heart', 'quality', 'taste', 'dont', 'lot', 'spend', 'cash', 'definitely', 'go', 'would', 'suggest', 'go', 'group', 'big', 'dont', 'mind', 'spend', 'entree', 'want', 'try', 'something', 'differentnew', 'look', 'make', 'romantic', 'occasion', 'really', 'special', 'let', 'restaurant', 'know', 'special', 'occasion', 'want', 'treat', 'someone', 'care', 'isnt', 'particular', 'general', 'something', 'havent', 'try', 'amazing_restaurant', 'restaurant_get', 'get_buy', 'buy_fondue', 'fondue_set', 'set_lol', 'lol_creamy', 'creamy_spinach', 'spinach_artichoke', 'artichoke_cheese', 'cheese_dip', 'dip_mince', 'mince_walnut', 'walnut_melt', 'melt_milk', 'milk_chocolate', 'chocolate_mixture', 'mixture_marinate', 'marinate_meat', 'meat_incredibly', 'incredibly_delicious', 'delicious_earn', 'earn_place', 'place_without', 'without_doubt', 'doubt_star', 'star_instead', 'instead_incredible', 'incredible_service', 'service_richard', 'richard_server', 'server_sociable', 'sociable_almost', 'almost_considerate', 'considerate_lol', 'lol_stay', 'stay_even', 'even_though', 'though_place', 'place_close', 'close_pm', 'pm_steve', 'steve_manager', 'manager_treat', 'treat_girlfriend', 'girlfriend_card', 'card_sign', 'sign_restaurant', 'restaurant_staff', 'staff_treat', 'treat_make', 'make_anniversary', 'anniversary_st', 'st_date', 'date_really', 'really_special', 'special_place', 'place_isnt', 'isnt_cheap', 'cheap_heart', 'heart_quality', 'quality_taste', 'taste_dont', 'dont_lot', 'lot_spend', 'spend_cash', 'cash_definitely', 'definitely_go', 'go_would', 'would_suggest', 'suggest_go', 'go_group', 'group_big', 'big_dont', 'dont_mind', 'mind_spend', 'spend_entree', 'entree_want', 'want_try', 'try_something', 'something_differentnew', 'differentnew_look', 'look_make', 'make_romantic', 'romantic_occasion', 'occasion_really', 'really_special', 'special_let', 'let_restaurant', 'restaurant_know', 'know_special', 'special_occasion', 'occasion_want', 'want_treat', 'treat_someone', 'someone_care', 'care_isnt', 'isnt_particular', 'particular_general', 'general_something', 'something_havent', 'havent_try'])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.2 s (started: 2021-04-12 13:41:39 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Examine one processed review\n",
    "processed_reviews.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2021-04-12 13:41:58 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "(trainingData, testData) = processed_reviews.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100469.6\n",
      "time: 0 ns (started: 2021-04-12 13:41:58 -04:00)\n"
     ]
    }
   ],
   "source": [
    "trainingData_count = subset_count * 0.8\n",
    "print(trainingData_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10min 8s (started: 2021-04-12 13:41:58 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Count vectorization with minDF and maxDF parameters\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "tfizer = CountVectorizer(inputCol = 'finished_ngrams', outputCol = 'tf_features', \n",
    "                         minDF = 0.01, maxDF = 0.1, vocabSize = int(trainingData_count / 2))\n",
    "\n",
    "tf_model = tfizer.fit(trainingData)\n",
    "tf_result_training = tf_model.transform(trainingData)\n",
    "tf_result_test = tf_model.transform(testData)\n",
    "\n",
    "idfizer = IDF(inputCol = 'tf_features', outputCol = 'tfidf_features')\n",
    "\n",
    "idf_model = idfizer.fit(tf_result_training)\n",
    "tfidf_result_training = idf_model.transform(tf_result_training)\n",
    "tfidf_result_test = idf_model.transform(tf_result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n",
      "time: 16 ms (started: 2021-04-12 13:52:07 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Print vocablary length (i.e. # of columns)\n",
    "print(len(tf_model.vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza',\n",
       " 'server',\n",
       " 'fry',\n",
       " 'meal',\n",
       " 'manager',\n",
       " 'sit',\n",
       " 'sauce',\n",
       " 'way',\n",
       " 'bar',\n",
       " 'friend',\n",
       " 'night',\n",
       " 'call',\n",
       " 'hour',\n",
       " 'find',\n",
       " 'two',\n",
       " 'thing',\n",
       " 'much',\n",
       " 'day',\n",
       " 'salad',\n",
       " 'serve',\n",
       " 'location',\n",
       " 'cheese',\n",
       " 'fresh',\n",
       " 'walk',\n",
       " 'everything',\n",
       " 'dish',\n",
       " 'right',\n",
       " 'long',\n",
       " 'another',\n",
       " 'still',\n",
       " 'burger',\n",
       " 'feel',\n",
       " 'seat',\n",
       " 'pay',\n",
       " 'review',\n",
       " 'work',\n",
       " 'little',\n",
       " 'cook',\n",
       " 'need',\n",
       " 'check',\n",
       " 'dinner',\n",
       " 'bring',\n",
       " 'waitress',\n",
       " 'around',\n",
       " 'visit',\n",
       " 'star',\n",
       " 'new',\n",
       " 'last',\n",
       " 'come_back',\n",
       " 'sure',\n",
       " 'lunch',\n",
       " 'sandwich',\n",
       " 'cant',\n",
       " 'use',\n",
       " 'every',\n",
       " 'next',\n",
       " 'meat',\n",
       " 'go_back',\n",
       " 'side',\n",
       " 'wasnt',\n",
       " 'since',\n",
       " 'favorite',\n",
       " 'year',\n",
       " 'small',\n",
       " 'vegas',\n",
       " 'open',\n",
       " 'many',\n",
       " 'something',\n",
       " 'top',\n",
       " 'close',\n",
       " 'lot',\n",
       " 'quality',\n",
       " 'start',\n",
       " 'sushi',\n",
       " 'away',\n",
       " 'late',\n",
       " 'hot',\n",
       " 'enjoy',\n",
       " 'flavor',\n",
       " 'seem',\n",
       " 'rice',\n",
       " 'roll',\n",
       " 'room',\n",
       " 'decide',\n",
       " 'worth',\n",
       " 'pretty',\n",
       " 'cold',\n",
       " 'taco',\n",
       " 'plate',\n",
       " 'family',\n",
       " 'put',\n",
       " 'customer_service',\n",
       " 'area',\n",
       " 'waiter',\n",
       " 'excellent',\n",
       " 'owner',\n",
       " 'horrible',\n",
       " 'let',\n",
       " 'super',\n",
       " 'money',\n",
       " 'nothing',\n",
       " 'return',\n",
       " 'big',\n",
       " 'awesome',\n",
       " 'steak',\n",
       " 'disappointed',\n",
       " 'bread',\n",
       " 'water',\n",
       " 'end',\n",
       " 'beer',\n",
       " 'special',\n",
       " 'happy',\n",
       " 'home',\n",
       " 'rude',\n",
       " 'soup',\n",
       " 'keep',\n",
       " 'half',\n",
       " 'breakfast',\n",
       " 'stop',\n",
       " 'offer',\n",
       " 'husband',\n",
       " 'busy',\n",
       " 'finally',\n",
       " 'old',\n",
       " 'terrible',\n",
       " 'guy',\n",
       " 'clean',\n",
       " 'anything',\n",
       " 'drive',\n",
       " 'arrive',\n",
       " 'wont',\n",
       " 'egg',\n",
       " 'business',\n",
       " 'else',\n",
       " 'different',\n",
       " 'beef',\n",
       " 'wrong',\n",
       " 'atmosphere',\n",
       " 'enough',\n",
       " 'portion',\n",
       " 'charge',\n",
       " 'point',\n",
       " 'spot',\n",
       " 'care',\n",
       " 'absolutely',\n",
       " 'stay',\n",
       " 'sweet',\n",
       " 'min',\n",
       " 'coffee',\n",
       " 'perfect',\n",
       " 'though',\n",
       " 'full',\n",
       " 'item',\n",
       " 'dessert',\n",
       " 'couldnt',\n",
       " 'pm',\n",
       " 'employee',\n",
       " 'youre',\n",
       " 'line',\n",
       " 'expect',\n",
       " 'thank',\n",
       " 'bit',\n",
       " 'shrimp',\n",
       " 'first_time',\n",
       " 'everyone',\n",
       " 'fish',\n",
       " 'party',\n",
       " 'option',\n",
       " 'actually',\n",
       " 'free',\n",
       " 'large',\n",
       " 'far',\n",
       " 'least',\n",
       " 'today',\n",
       " 'show',\n",
       " 'inside',\n",
       " 'ok',\n",
       " 'fast',\n",
       " 'wing',\n",
       " 'kid',\n",
       " 'pork',\n",
       " 'without',\n",
       " 'hand',\n",
       " 'ice',\n",
       " 'bill',\n",
       " 'almost',\n",
       " 'front',\n",
       " 'someone',\n",
       " 'run',\n",
       " 'appetizer',\n",
       " 'hard',\n",
       " 'wife',\n",
       " 'person',\n",
       " 'must',\n",
       " 'spicy',\n",
       " 'week',\n",
       " 'talk',\n",
       " 'highly',\n",
       " 'second',\n",
       " 'however',\n",
       " 'pick',\n",
       " 'kind',\n",
       " 'add',\n",
       " 'receive',\n",
       " 'change',\n",
       " 'name',\n",
       " 'potato',\n",
       " 'la',\n",
       " 'maybe',\n",
       " 'probably',\n",
       " 'tasty',\n",
       " 'dry',\n",
       " 'town',\n",
       " 'cream',\n",
       " 'piece',\n",
       " 'ill',\n",
       " 'high',\n",
       " 'extra',\n",
       " 'couple',\n",
       " 'noodle',\n",
       " 'dining',\n",
       " 'live',\n",
       " 'extremely',\n",
       " 'door',\n",
       " 'help',\n",
       " 'kitchen',\n",
       " 'wine',\n",
       " 'huge',\n",
       " 'instead',\n",
       " 'tip',\n",
       " 'reservation',\n",
       " 'outside',\n",
       " 'bartender',\n",
       " 'house',\n",
       " 'three',\n",
       " 'whole',\n",
       " 'tea',\n",
       " 'happen',\n",
       " 'bowl',\n",
       " 'chef',\n",
       " 'bite',\n",
       " 'group',\n",
       " 'doesnt',\n",
       " 'oh',\n",
       " 'finish',\n",
       " 'chip',\n",
       " 'fantastic',\n",
       " 'hear',\n",
       " 'grill',\n",
       " 'taste_like',\n",
       " 'forget',\n",
       " 'highly_recommend',\n",
       " 'hotel',\n",
       " 'usually',\n",
       " 'buffet',\n",
       " 'selection',\n",
       " 'wonderful',\n",
       " 'spend',\n",
       " 'slow',\n",
       " 'girl',\n",
       " 'anyone',\n",
       " 'phone',\n",
       " 'poor',\n",
       " 'already',\n",
       " 'please',\n",
       " 'id',\n",
       " 'size',\n",
       " 'speak',\n",
       " 'stand',\n",
       " 'lady',\n",
       " 'course',\n",
       " 'ive_ever',\n",
       " 'quick',\n",
       " 'hope',\n",
       " 'several',\n",
       " 'part',\n",
       " 'great_food',\n",
       " 'choice',\n",
       " 'mean',\n",
       " 'quite',\n",
       " 'either',\n",
       " 'cake',\n",
       " 'waste',\n",
       " 'wish',\n",
       " 'include',\n",
       " 'turn',\n",
       " 'park',\n",
       " 'yelp',\n",
       " 'treat',\n",
       " 'green',\n",
       " 'fill',\n",
       " 'store',\n",
       " 'less',\n",
       " 'yet',\n",
       " 'especially',\n",
       " 'overall',\n",
       " 'problem',\n",
       " 'warm',\n",
       " 'mexican',\n",
       " 'bean',\n",
       " 'fun',\n",
       " 'card',\n",
       " 'thai',\n",
       " 'hostess',\n",
       " 'look_like',\n",
       " 'ready',\n",
       " 'bacon',\n",
       " 'empty',\n",
       " 'onion',\n",
       " 'wouldnt',\n",
       " 'glass',\n",
       " 'understand',\n",
       " 'watch',\n",
       " 'attentive',\n",
       " 'awful',\n",
       " 'literally',\n",
       " 'take_order',\n",
       " 'birthday',\n",
       " 'choose',\n",
       " 'rib',\n",
       " 'food_good',\n",
       " 'move',\n",
       " 'deal',\n",
       " 'management',\n",
       " 'regular',\n",
       " 'love_place',\n",
       " 'write',\n",
       " 'local',\n",
       " 'counter',\n",
       " 'burrito',\n",
       " 'soon',\n",
       " 'share',\n",
       " 'yes',\n",
       " 'notice',\n",
       " 'surprise',\n",
       " 'stuff',\n",
       " 'completely',\n",
       " 'sorry',\n",
       " 'cheap',\n",
       " 'strip',\n",
       " 'cool',\n",
       " 'miss',\n",
       " 'great_service',\n",
       " 'mention',\n",
       " 'feel_like',\n",
       " 'real',\n",
       " 'guess',\n",
       " 'reason',\n",
       " 'ago',\n",
       " 'slice',\n",
       " 'bbq',\n",
       " 'greet',\n",
       " 'pasta',\n",
       " 'make_sure',\n",
       " 'amount',\n",
       " 'dirty',\n",
       " 'red',\n",
       " 'light',\n",
       " 'cut',\n",
       " 'attitude',\n",
       " 'isnt',\n",
       " 'entire',\n",
       " 'life',\n",
       " 'delivery',\n",
       " 'food_great',\n",
       " 'believe',\n",
       " 'crab',\n",
       " 'bland',\n",
       " 'get_food',\n",
       " 'man',\n",
       " 'chinese',\n",
       " 'month',\n",
       " 'really_good',\n",
       " 'explain',\n",
       " 'fine',\n",
       " 'music',\n",
       " 'wait_minute',\n",
       " 'twice',\n",
       " 'street',\n",
       " 'wow',\n",
       " 'deliver',\n",
       " 'issue',\n",
       " 'buy',\n",
       " 'tomato',\n",
       " 'establishment',\n",
       " 'good_food',\n",
       " 'read',\n",
       " 'game',\n",
       " 'every_time',\n",
       " 'throw',\n",
       " 'may',\n",
       " 'italian',\n",
       " 'list',\n",
       " 'never_go',\n",
       " 'send',\n",
       " 'prepare',\n",
       " 'fact',\n",
       " 'chocolate',\n",
       " 'okay',\n",
       " 'authentic',\n",
       " 'perfectly',\n",
       " 'style',\n",
       " 'job',\n",
       " 'decent',\n",
       " 'able',\n",
       " 'tonight',\n",
       " 'plus',\n",
       " 'crispy',\n",
       " 'theyre',\n",
       " 'early',\n",
       " 'food_service',\n",
       " 'short',\n",
       " 'past',\n",
       " 'shop',\n",
       " 'mix',\n",
       " 'dont_know',\n",
       " 'behind',\n",
       " 'lack',\n",
       " 'cup',\n",
       " 'dog',\n",
       " 'white',\n",
       " 'la_vegas',\n",
       " 'brunch',\n",
       " 'garlic',\n",
       " 'seriously',\n",
       " 'mind',\n",
       " 'next_time',\n",
       " 'happy_hour',\n",
       " 'ingredient',\n",
       " 'boyfriend',\n",
       " 'french',\n",
       " 'even_though',\n",
       " 'disgusting',\n",
       " 'might',\n",
       " 'season',\n",
       " 'toast',\n",
       " 'patio',\n",
       " 'burn',\n",
       " 'guest',\n",
       " 'set',\n",
       " 'saturday',\n",
       " 'salsa',\n",
       " 'play',\n",
       " 'trip',\n",
       " 'sunday',\n",
       " 'salmon',\n",
       " 'vegan',\n",
       " 'complain',\n",
       " 'hungry',\n",
       " 'type',\n",
       " 'welcome',\n",
       " 'cocktail',\n",
       " 'sign',\n",
       " 'yummy',\n",
       " 'quickly',\n",
       " 'helpful',\n",
       " 'request',\n",
       " 'smell',\n",
       " 'butter',\n",
       " 'fan',\n",
       " 'totally',\n",
       " 'remember',\n",
       " 'tender',\n",
       " 'didnt_even',\n",
       " 'pull',\n",
       " 'dress',\n",
       " 'expensive',\n",
       " 'box',\n",
       " 'head',\n",
       " 'service_great',\n",
       " 'morning',\n",
       " 'rest',\n",
       " 'refill',\n",
       " 'weekend',\n",
       " 'state',\n",
       " 'seafood',\n",
       " 'floor',\n",
       " 'recommend_place',\n",
       " 'lobster',\n",
       " 'save',\n",
       " 'friday',\n",
       " 'immediately',\n",
       " 'together',\n",
       " 'decor',\n",
       " 'pepper',\n",
       " 'disappointing',\n",
       " 'sad',\n",
       " 'rather',\n",
       " 'suppose',\n",
       " 'stick',\n",
       " 'mess',\n",
       " 'beautiful',\n",
       " 'suck',\n",
       " 'ice_cream',\n",
       " 'mouth',\n",
       " 'mistake',\n",
       " 'simple',\n",
       " 'honestly',\n",
       " 'black',\n",
       " 'last_time',\n",
       " 'cost',\n",
       " 'pancake',\n",
       " 'chance',\n",
       " 'dollar',\n",
       " 'base',\n",
       " 'food_come',\n",
       " 'meet',\n",
       " 'eye',\n",
       " 'apologize',\n",
       " 'never_come',\n",
       " 'werent',\n",
       " 'bad_service',\n",
       " 'mac',\n",
       " 'crust',\n",
       " 'great_place',\n",
       " 'often',\n",
       " 'one_good',\n",
       " 'window',\n",
       " 'although',\n",
       " 'lose',\n",
       " 'rate',\n",
       " 'bottle',\n",
       " 'near',\n",
       " 'pass',\n",
       " 'date',\n",
       " 'word',\n",
       " 'mushroom',\n",
       " 'impressed',\n",
       " 'havent',\n",
       " 'pack',\n",
       " 'grab',\n",
       " 'minute_late',\n",
       " 'across',\n",
       " 'place_go',\n",
       " 'wrap',\n",
       " 'low',\n",
       " 'excited',\n",
       " 'weve',\n",
       " 'break',\n",
       " 'avoid',\n",
       " 'anyway',\n",
       " 'place_order',\n",
       " 'thru',\n",
       " 'five',\n",
       " 'gross',\n",
       " 'freeze',\n",
       " 'four',\n",
       " 'main',\n",
       " 'dip',\n",
       " 'unfortunately',\n",
       " 'variety',\n",
       " 'crowd',\n",
       " 'daughter',\n",
       " 'bag',\n",
       " 'car',\n",
       " 'glad',\n",
       " 'salt',\n",
       " 'woman',\n",
       " 'clearly',\n",
       " 'reasonable',\n",
       " 'answer',\n",
       " 'mediocre',\n",
       " 'last_night',\n",
       " 'cashier',\n",
       " 'time_go',\n",
       " 'worker',\n",
       " 'due',\n",
       " 'would_recommend',\n",
       " 'bun',\n",
       " 'curry',\n",
       " 'salty',\n",
       " 'smile',\n",
       " 'order_food',\n",
       " 'suggest',\n",
       " 'hair',\n",
       " 'son',\n",
       " 'hold',\n",
       " 'consider',\n",
       " 'number',\n",
       " 'plenty',\n",
       " 'simply',\n",
       " 'young',\n",
       " 'attention',\n",
       " 'flavorful',\n",
       " 'provide',\n",
       " 'good_service',\n",
       " 'easy',\n",
       " 'bother',\n",
       " 'average',\n",
       " 'face',\n",
       " 'realize',\n",
       " 'n',\n",
       " 'total',\n",
       " 'lettuce',\n",
       " 'sausage',\n",
       " 'overpriced',\n",
       " 'begin',\n",
       " 'available',\n",
       " 'medium',\n",
       " 'single',\n",
       " 'cafe',\n",
       " 'bad_experience',\n",
       " 'question',\n",
       " 'plan',\n",
       " 'city',\n",
       " 'smoke',\n",
       " 'ambiance',\n",
       " 'hit',\n",
       " 'vegetable',\n",
       " 'spice',\n",
       " 'zero',\n",
       " 'refund',\n",
       " 'service_food',\n",
       " 'soft',\n",
       " 'picture',\n",
       " 'cant_wait',\n",
       " 'long_time',\n",
       " 'along',\n",
       " 'ignore',\n",
       " 'online',\n",
       " 'take_minute',\n",
       " 'barely',\n",
       " 'world',\n",
       " 'get_order',\n",
       " 'tuna',\n",
       " 'die',\n",
       " 'corn',\n",
       " 'bathroom',\n",
       " 'soggy',\n",
       " 'somewhere',\n",
       " 'hang',\n",
       " 'drop',\n",
       " 'rush',\n",
       " 'cannot',\n",
       " 'loud',\n",
       " 'drive_thru',\n",
       " 'upon',\n",
       " 'try_place',\n",
       " 'dine',\n",
       " 'idea',\n",
       " 'forward',\n",
       " 'continue',\n",
       " 'truly',\n",
       " 'fix',\n",
       " 'combo',\n",
       " 'quality_food',\n",
       " 'margarita',\n",
       " 'sick',\n",
       " 'figure',\n",
       " 'interest',\n",
       " 'staff_friendly',\n",
       " 'vegetarian',\n",
       " 'accommodate',\n",
       " 'outstanding',\n",
       " 'th',\n",
       " 'basically',\n",
       " 'wall',\n",
       " 'etc',\n",
       " 'chili',\n",
       " 'good_thing',\n",
       " 'greasy',\n",
       " 'fall',\n",
       " 'cover',\n",
       " 'brown',\n",
       " 'bake',\n",
       " 'sour',\n",
       " 'youll',\n",
       " 'cash',\n",
       " 'beyond',\n",
       " 'definitely_back',\n",
       " 'incredible',\n",
       " 'seem_like',\n",
       " 'phoenix',\n",
       " 'gem',\n",
       " 'note',\n",
       " 'joint',\n",
       " 'level',\n",
       " 'obviously',\n",
       " 'crave',\n",
       " 'book',\n",
       " 'raw',\n",
       " 'give_place',\n",
       " 'anywhere',\n",
       " 'forever',\n",
       " 'view',\n",
       " 'unique',\n",
       " 'become',\n",
       " 'hate',\n",
       " 'tiny',\n",
       " 'melt',\n",
       " 'matter',\n",
       " 'entrees',\n",
       " 'inform',\n",
       " 'veggies',\n",
       " 'ridiculous',\n",
       " 'oil',\n",
       " 'multiple',\n",
       " 'follow',\n",
       " 'toppings',\n",
       " 'thin',\n",
       " 'allow',\n",
       " 'definitely_come',\n",
       " 'post',\n",
       " 'unless',\n",
       " 'mexican_food',\n",
       " 'one_star',\n",
       " 'space',\n",
       " 'im_sure',\n",
       " 'cause',\n",
       " 'food_amazing',\n",
       " 'food_delicious',\n",
       " 'refuse',\n",
       " 'touch',\n",
       " 'fast_food',\n",
       " 'much_well',\n",
       " 'joke',\n",
       " 'clear',\n",
       " 'correct',\n",
       " 'drink_order',\n",
       " 'pleasant',\n",
       " 'complaint',\n",
       " 'make_feel',\n",
       " 'apparently',\n",
       " 'lol',\n",
       " 'standard',\n",
       " 'roast',\n",
       " 'recommendation',\n",
       " 'waste_time',\n",
       " 'whatever',\n",
       " 'within',\n",
       " 'sell',\n",
       " 'healthy',\n",
       " 'middle',\n",
       " 'disappointment',\n",
       " 'entree',\n",
       " 'rock',\n",
       " 'one_favorite',\n",
       " 'none',\n",
       " 'minute_get',\n",
       " 'non',\n",
       " 'wait_staff',\n",
       " 'tasteless',\n",
       " 'per',\n",
       " 'deserve',\n",
       " 'make_reservation',\n",
       " 'ive_never',\n",
       " 'negative',\n",
       " 'say_would',\n",
       " 'heat',\n",
       " 'sit_bar',\n",
       " 'cute',\n",
       " 'vibe',\n",
       " 'dining_experience',\n",
       " 'recently',\n",
       " 'ahead',\n",
       " 'proceed',\n",
       " 'handle',\n",
       " 'sound',\n",
       " 'service_good',\n",
       " 'could_give',\n",
       " 'look_forward',\n",
       " 'time_come',\n",
       " 'case',\n",
       " 'apology',\n",
       " 'homemade',\n",
       " 'friendly_staff',\n",
       " 'arent',\n",
       " 'exactly',\n",
       " 'value',\n",
       " 'didnt_want',\n",
       " 'appreciate',\n",
       " 'pretty_good',\n",
       " 'second_time',\n",
       " 'elsewhere',\n",
       " 'anymore',\n",
       " 'order_take',\n",
       " 'food_order',\n",
       " 'good_place',\n",
       " 'place_great',\n",
       " 'go_place',\n",
       " 'time_get',\n",
       " 'place_eat',\n",
       " 'wonder',\n",
       " 'would_definitely',\n",
       " 'give_star']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms (started: 2021-04-12 13:52:07 -04:00)\n"
     ]
    }
   ],
   "source": [
    "tf_model.vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62 ms (started: 2021-04-12 13:52:07 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Define logistic regression with ridge\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# lr = LogisticRegression(featuresCol = 'tfidf_features', labelCol = 'stars')\n",
    "lr = LogisticRegression(featuresCol = 'tfidf_features', labelCol = 'categoryIndex', \n",
    "                        family = 'binomial', elasticNetParam = 0, regParam = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'threshold': 0.5,\n",
       " 'aggregationDepth': 2,\n",
       " 'standardization': True,\n",
       " 'fitIntercept': True,\n",
       " 'elasticNetParam': 0.0,\n",
       " 'predictionCol': 'prediction',\n",
       " 'featuresCol': 'tfidf_features',\n",
       " 'labelCol': 'categoryIndex',\n",
       " 'rawPredictionCol': 'rawPrediction',\n",
       " 'probabilityCol': 'probability',\n",
       " 'maxIter': 100,\n",
       " 'regParam': 0.1,\n",
       " 'tol': 1e-06,\n",
       " 'family': 'binomial'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 13:52:07 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Print all parameters\n",
    "{param[0].name: param[1] for param in lr.extractParamMap().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5min 8s (started: 2021-04-12 13:52:07 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Fit LR model\n",
    "lrModel = lr.fit(tfidf_result_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 78 ms (started: 2021-04-12 13:57:15 -04:00)\n"
     ]
    }
   ],
   "source": [
    "lrPredictions_training = lrModel.transform(tfidf_result_training)\n",
    "lrPredictions_test = lrModel.transform(tfidf_result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2021-04-12 13:57:15 -04:00)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'categoryIndex', predictionCol = 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9min 56s (started: 2021-04-12 13:57:16 -04:00)\n"
     ]
    }
   ],
   "source": [
    "acc_training_lr = evaluator.evaluate(lrPredictions_training, {evaluator.metricName: \"accuracy\"})\n",
    "acc_test_lr = evaluator.evaluate(lrPredictions_test, {evaluator.metricName: \"accuracy\"})\n",
    "# f1 = evaluator.evaluate(lrPredictions_training, {evaluator.metricName: \"f1\"})\n",
    "# weightedPrecision = evaluator.evaluate(lrPredictions_training, {evaluator.metricName: \"weightedPrecision\"})\n",
    "# weightedRecall = evaluator.evaluate(lrPredictions_training, {evaluator.metricName: \"weightedRecall\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9404485000298205\n",
      "Test accuracy: 0.9425255153091855\n",
      "time: 0 ns (started: 2021-04-12 14:07:12 -04:00)\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy: ' + str(acc_training_lr))\n",
    "print('Test accuracy: ' + str(acc_test_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2021-04-12 14:07:12 -04:00)\n"
     ]
    }
   ],
   "source": [
    "coef_matrix = lrModel.coefficientMatrix\n",
    "coef_list = coef_matrix.toArray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-0.225919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.220192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>-0.195700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.192852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>-0.190591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.191573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.194716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.199487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.221117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.232031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "124 -0.225919\n",
       "96  -0.220192\n",
       "561 -0.195700\n",
       "113 -0.192852\n",
       "485 -0.190591\n",
       "..        ...\n",
       "61   0.191573\n",
       "325  0.194716\n",
       "709  0.199487\n",
       "94   0.221117\n",
       "103  0.232031\n",
       "\n",
       "[785 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 657 ms (started: 2021-04-12 14:07:12 -04:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(coef_list).T.sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terrible\n",
      "horrible\n",
      "mediocre\n",
      "rude\n",
      "disappointing\n",
      "overpriced\n",
      "awful\n",
      "bland\n",
      "bad_service\n",
      "disgusting\n",
      "never_go\n",
      "poor\n",
      "waste\n",
      "tasteless\n",
      "one_star\n",
      "suck\n",
      "slow\n",
      "never_come\n",
      "gross\n",
      "dry\n",
      "time: 171 ms (started: 2021-04-12 14:07:13 -04:00)\n"
     ]
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(coef_list).T.sort_values(0, ascending = True)\n",
    "for i in range(0, 20):\n",
    "    print(tf_model.vocabulary[coef_df.index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awesome\n",
      "excellent\n",
      "food_amazing\n",
      "love_place\n",
      "favorite\n",
      "fantastic\n",
      "definitely_back\n",
      "cant_wait\n",
      "perfect\n",
      "food_delicious\n",
      "great_service\n",
      "great_food\n",
      "one_good\n",
      "gem\n",
      "yummy\n",
      "friendly_staff\n",
      "definitely_come\n",
      "highly_recommend\n",
      "outstanding\n",
      "wonderful\n",
      "time: 156 ms (started: 2021-04-12 14:07:13 -04:00)\n"
     ]
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(coef_list).T.sort_values(0, ascending = False)\n",
    "for i in range(0, 20):\n",
    "    print(tf_model.vocabulary[coef_df.index[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms (started: 2021-04-12 14:31:42 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.classification import RandomForestClassifier\n",
    "# rf = RandomForestClassifier(featuresCol = 'tfidf_features', labelCol = 'categoryIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': -7873517711665355170,\n",
       " 'maxDepth': 5,\n",
       " 'maxBins': 32,\n",
       " 'minInstancesPerNode': 1,\n",
       " 'minInfoGain': 0.0,\n",
       " 'maxMemoryInMB': 256,\n",
       " 'cacheNodeIds': False,\n",
       " 'checkpointInterval': 10,\n",
       " 'impurity': 'gini',\n",
       " 'numTrees': 20,\n",
       " 'featureSubsetStrategy': 'auto',\n",
       " 'subsamplingRate': 1.0,\n",
       " 'leafCol': '',\n",
       " 'minWeightFractionPerNode': 0.0,\n",
       " 'bootstrap': True,\n",
       " 'predictionCol': 'prediction',\n",
       " 'featuresCol': 'tfidf_features',\n",
       " 'labelCol': 'categoryIndex',\n",
       " 'rawPredictionCol': 'rawPrediction',\n",
       " 'probabilityCol': 'probability'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 14:31:43 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# {param[0].name: param[1] for param in rf.extractParamMap().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19min 43s (started: 2021-04-12 14:31:43 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# rfModel = rf.fit(tfidf_result_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 94 ms (started: 2021-04-12 14:51:26 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# rfPredictions_training = rfModel.transform(tfidf_result_training)\n",
    "# rfPredictions_test = rfModel.transform(tfidf_result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11min 7s (started: 2021-04-12 14:51:26 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# acc_training_rf = evaluator.evaluate(rfPredictions_training, {evaluator.metricName: \"accuracy\"})\n",
    "# acc_test_rf = evaluator.evaluate(rfPredictions_test, {evaluator.metricName: \"accuracy\"})\n",
    "# # f1 = evaluator.evaluate(rfPredictions_training, {evaluator.metricName: \"f1\"})\n",
    "# # weightedPrecision = evaluator.evaluate(rfPredictions_training, {evaluator.metricName: \"weightedPrecision\"})\n",
    "# # weightedRecall = evaluator.evaluate(rfPredictions_training, {evaluator.metricName: \"weightedRecall\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8163555396512991\n",
      "Test accuracy: 0.8170502301380829\n",
      "time: 0 ns (started: 2021-04-12 15:02:34 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# print('Training accuracy: ' + str(acc_training_rf))\n",
    "# print('Test accuracy: ' + str(acc_test_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms (started: 2021-04-12 15:02:34 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# coef_matrix = rfModel.featureImportances\n",
    "# coef_list = coef_matrix.toArray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terrible\n",
      "rude\n",
      "horrible\n",
      "money\n",
      "awful\n",
      "cold\n",
      "awesome\n",
      "highly_recommend\n",
      "charge\n",
      "another\n",
      "pay\n",
      "favorite\n",
      "wasnt\n",
      "fantastic\n",
      "tasty\n",
      "attitude\n",
      "excellent\n",
      "perfect\n",
      "disgusting\n",
      "min\n",
      "wonderful\n",
      "seem\n",
      "never_go\n",
      "wont\n",
      "dirty\n",
      "wait_minute\n",
      "bill\n",
      "arrive\n",
      "atmosphere\n",
      "sorry\n",
      "perfectly\n",
      "walk\n",
      "employee\n",
      "waste\n",
      "put\n",
      "receive\n",
      "nothing\n",
      "dry\n",
      "slow\n",
      "finally\n",
      "time: 390 ms (started: 2021-04-12 15:02:34 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# coef_df = pd.DataFrame(coef_list).sort_values(0, ascending = False)\n",
    "# for i in range(0, 40):\n",
    "#     print(tf_model.vocabulary[coef_df.index[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark LDA topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 14:07:14 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.ml.clustering import LDA\n",
    "# num_topics = 10\n",
    "# max_iter = 10\n",
    "# lda = LDA(k = num_topics, \n",
    "#           maxIter = max_iter, \n",
    "#           featuresCol = 'tfidf_features')\n",
    "# lda_model = lda.fit(tfidf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 14:07:14 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import types as T\n",
    "# vocab = tf_model.vocabulary\n",
    "# def get_words(token_list):\n",
    "#     return [vocab[token_id] for token_id in token_list]\n",
    "# udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2021-04-12 14:07:14 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# num_top_words = 10\n",
    "# topics = lda_model \\\n",
    "# .describeTopics(num_top_words) \\\n",
    "# .withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
    "# topics.select('topic', 'topicWords').show(truncate = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
